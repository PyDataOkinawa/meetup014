{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggleで遊ぼう\n",
    "\n",
    "## 今回のお題：[kaggle - Shelter Animal Outcomes](https://www.kaggle.com/c/shelter-animal-outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ４つの基本ステップ\n",
    "\n",
    "1. 準備（データを落として来たり、ライブラリを読み込んだりする）\n",
    "2. データ整形（予測に効きそうな特徴量をうまくデザインしながら、全ての情報を数値データに変換する）\n",
    "3. 機械学習（交差検定を駆使してモデルごとに程よいハイパーパラメータを選び、最後にアンサンブル学習）\n",
    "4. 結果提出（予測結果をCSVファイルに書き出して、kaggleに提出）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ１：準備\n",
    "\n",
    "目的：データを用意し、ライブラリを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ディレクトリ構成を揃える（input, output, code）\n",
    "#!ls -la .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# データ整形と可視化で必要となるライブラリを読み込む\n",
    "\n",
    "# 数値計算用ライブラリ\n",
    "<FILL_IN>\n",
    "\n",
    "# データ解析用ライブラリ\n",
    "<FILL_IN>\n",
    "\n",
    "# 基本の描画ライブラリ（２つ）\n",
    "<FILL_IN>\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 便利な設定\n",
    "\n",
    "# 図をipython notebook内で表示\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ２：データ整形\n",
    "\n",
    "目的：データの特徴を理解し、機械学習ができる形に整形する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データを読み込む\n",
    "\n",
    "- `pd.read_csv()`を使うと良い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "df_train = <FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = <FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sub = <FILL_IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データを眺める\n",
    "\n",
    "#### データを眺めるときに使える関数\n",
    "- `df.head()`, `df.tail()`\n",
    "- `df.info()`\n",
    "- `df.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの結合\n",
    "\n",
    "- 整形のため（特に欠損値を埋めるため）、トレーニングデータとテストデータを合わせる\n",
    "- 注：本来であればトレーニングデータで得た知見だけを使い、トレーニングデータとテストデータの欠損値を埋めるべきだが、簡単のため今回はこうする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 一応、AnimalIDとIDがユニークな値であることを確認\n",
    "\n",
    "# トレーニングデータ\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# テストデータ\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# テストデータとの整合性を保つため、トレーニングデータのAnimalIDというカラム名をIDに変更する\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# IDというカラムをインデックスとする\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 後でデータを分離しやすいよう、結合前にトレーニングデータとテストデータがわかるようなラベルを振っておく\n",
    "df_train['_data'] = 'train'\n",
    "df_test['_data'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# データセットを結合する\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 一応、データの形をチェック\n",
    "print df.shape\n",
    "print df_train.shape\n",
    "print df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 出力特徴量（従属変数）の整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 欠損値に関する情報を得る\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome_labels = ['Adoption', 'Died', 'Euthanasia', 'Return_to_owner', 'Transfer']\n",
    "outcome2id = dict(zip(*[outcome_labels, np.arange(5)]))\n",
    "outcome2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# zip()の使用例\n",
    "zip(*[['a', 'b'], [1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 最終的に予測するターゲット\n",
    "df['OutcomeTypeId'] = df['OutcomeType'].map(outcome2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使わない変数はこのリストに保持\n",
    "# 後で、df.drop(not_needed, axis=1, inplace=True) とすることで、いらない列を落とせる。\n",
    "# 予測に使用する変数が増えて来たときに活躍する。\n",
    "# 今回は簡単のため、OutcomeSubtypeは無視する。\n",
    "not_needed = ['OutcomeType', 'OutcomeSubtype']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力特徴量（独立変数）の整形"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AgeuponOutcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_needed.append('AgeuponOutcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AnimalType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 生データを眺める\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 欠損値に関する情報を得る\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 犬と猫の数を調べる\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 犬と猫でどう違うのか見る\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 　描画\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 猫と犬、それぞれにおけるターゲットの割合を計算\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 描画\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "animal_type2id = {'Dog': 0, 'Cat': 1}\n",
    "df['AnimalTypeId'] = df['AnimalType'].map(animal_type2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_needed.append('AnimalType')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_needed.append('Breed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_needed.append('Color')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_needed.append('DateTime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 欠損値について調べる\n",
    "#<FILL_IN_LATER>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 「名前が無い」ということは重要な特徴かもしれない\n",
    "#<FILL_IN_LATER>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 各要素の頻度を調べる\n",
    "#<FILL_IN_LATER>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 名前の頻度をNameCountという変数にする\n",
    "#<FILL_IN_LATER>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NameCountの欠損値を1で埋める\n",
    "df['NameCount'] = <FILL_IN_LATER>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df['NameCount'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NameCountを対数変換したLogNameCountという変数を作る\n",
    "#df['LogNameCount'] = <FILL_IN_LATER>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df['LogNameCount'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 名前の文字数。名前が無い場合は0とした。\n",
    "#df['NameLength'] = df['Name'].fillna('').apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 名前と名前の文字数が一致しているか確認\n",
    "#df[['Name', 'NameLength']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_needed.append('Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SexuponOutcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_needed.append('SexuponOutcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn用にデータ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#input_features = ['AnimalTypeId']\n",
    "#input_features = ['AnimalTypeId', 'NameCount']\n",
    "#input_features = ['AnimalTypeId', 'LogNameCount']\n",
    "#input_features = ['AnimalTypeId', 'NameCount', 'LogNameCount']\n",
    "#input_features = ['AnimalTypeId', 'NameCount', 'LogNameCount']\n",
    "#input_features = ['AnimalTypeId', 'NameCount', 'LogNameCount', 'NameIsNull']\n",
    "#input_features = ['AnimalTypeId', 'NameCount', 'LogNameCount', 'NameIsNull', 'NameLength']\n",
    "output_feature = 'OutcomeTypeId'\n",
    "input_features = df.columns.difference(not_needed + [output_feature, '_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# トレーニングデータの入力特徴量を用意（２次元）\n",
    "X_train = df.ix[df['_data'] == 'train', input_features].values.astype('float')\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# トレーニングデータの出力特徴量を用意（１次元）\n",
    "# 1次元で用意するためには、Seriesから値を取り出せば良い。もしくはflatten()を使う\n",
    "y_train = df.ix[df['_data'] == 'train', output_feature].values.astype('int')\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# テストデータの入力特徴量を用意（２次元）\n",
    "X_test = df.ix[df['_data'] == 'test', input_features].values.astype('float')\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スケーリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# StandardScalerオブジェクトを作成\n",
    "scaler = <FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# トレーニングデータのデータでフィッティング\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 通常バイナリデータはスケーリングの対象としないが、今回はざっくりと全入力変数をスケーリングしてしまう\n",
    "X_train = <FILL_IN>\n",
    "X_test = <FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print u\"トレーニングデータ\"\n",
    "print X_train.mean(axis=0)\n",
    "print X_train.std(axis=0)\n",
    "print u\"テストデータ\"\n",
    "print X_test.mean(axis=0)\n",
    "print X_test.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ３：機械学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 学習\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# テストデータの出力を予測\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ステップ４：結果提出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 予測結果をデータフレームに入れる\n",
    "df_result = pd.DataFrame(y_test_pred, columns=outcome_labels, index=df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# データフレームからsubmission01.csvに書き出し\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （おまけ）しかし、毎回kaggleに投げるのは問題あり..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 交差検定をサクッとやるためのモジュールを読み込む\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_scores = <FILL_IN>\n",
    "print\"{0:.3f} ({1:.3f})\".format(cv_scores.mean(), cv_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （おまけ）他のモデルだとどうなるだろう？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 予測モデルの読み込み\n",
    "\n",
    "# 分類モデル（他にもいろいろある）\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "#from xgboost import XGBClassifier # これだけ個別にインストールする必要あり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    ('lr', LogisticRegression()), \n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    #('linear svc', SVC(kernel=\"linear\")), # データ点が多いと計算に時間がかかるので今回は割愛\n",
    "    #('rbf svc', SVC(gamma=2)), # データ点が多いと計算に時間がかかるので今回は割愛\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('et', ExtraTreesClassifier()),\n",
    "    ('ab', AdaBoostClassifier()),\n",
    "    ('gbc', GradientBoostingClassifier()),\n",
    "    ('gnb', GaussianNB()),\n",
    "    ('lda', LinearDiscriminantAnalysis()),\n",
    "    ('qda', QuadraticDiscriminantAnalysis()),\n",
    "    #('xgb', XGBClassifier()) # これだけ個別にインストールする必要があるので今回は割愛\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import time\n",
    "results = {}\n",
    "exec_times = {}\n",
    "\n",
    "for name, model in classifiers:\n",
    "    tic = time.time()\n",
    "    if name in ['linear svc', 'rbf svc']:\n",
    "        result = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')        \n",
    "    else:\n",
    "        result = cross_val_score(model, X_train, y_train, cv=5, scoring='log_loss')\n",
    "    exec_time = time.time() - tic\n",
    "    exec_times[name] = exec_time\n",
    "    results[name] = result\n",
    "    \n",
    "    print(\"{0:.3f} ({1:.3f}): time {2:.2f}s, {3}\".format(result.mean(), result.std(), exec_time, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# 結果の描画を楽にするためpandasのデータフレームに結果を入れる\n",
    "import pandas as pd\n",
    "\n",
    "dfr = pd.DataFrame(results)\n",
    "\n",
    "dfr[dfr.median().sort_values(ascending=True).index].boxplot(vert=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （おまけ）特徴量の重要度を見たいときには？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "fi = model.feature_importances_\n",
    "plt.barh(np.arange(len(fi)), fi);\n",
    "plt.yticks(np.arange(len(fi))+0.4, input_features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df0 = df[input_features.union(['_data'])]\n",
    "df0 = df0[df0['_data'] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.get_dummies(df_train['OutcomeType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df01 = df0.join(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df01.drop('_data', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(df01.corr(), ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （おまけ）ハイパーパラメータの選び方は？\n",
    "\n",
    "- １次元: validation_curve\n",
    "- 低次元: GridSearchCV\n",
    "- 高次元: RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 交差検証\n",
    "from sklearn.learning_curve import validation_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_name = 'max_depth'\n",
    "#param_name = 'n_estimators'\n",
    "\n",
    "param_range = {\n",
    "    'max_depth': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'n_estimators': [10, 20, 40, 80, 160],\n",
    "    #'n_estimators': [40, 60, 80, 100, 120, 140, 160],\n",
    "}\n",
    "\n",
    "fixed_params = {\n",
    "#    'max_depth': 2\n",
    "}\n",
    "\n",
    "train_scores, valid_scores = validation_curve(GradientBoostingClassifier(**fixed_params), \n",
    "                                              X_train, y_train, \n",
    "                                              scoring='log_loss',\n",
    "                                              cv = 3,\n",
    "                                              param_name=param_name, \n",
    "                                              param_range=param_range[param_name], \n",
    "                                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_validation_curve(train_scores, valid_scores, param_range, semilogx=False):\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "    valid_scores_std = np.std(valid_scores, axis=1)\n",
    "\n",
    "    if semilogx:\n",
    "        plot = plt.semilogx\n",
    "    else:\n",
    "        plot = plt.plot\n",
    "    \n",
    "    plt.title(\"Validation Curve\")\n",
    "    plt.xlabel(\"Hyperparameter\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    #plt.ylim(0.0, 1.1)\n",
    "    plot(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2, color=\"r\")\n",
    "    plot(param_range, valid_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"g\")\n",
    "    plt.fill_between(param_range, valid_scores_mean - valid_scores_std,\n",
    "                     valid_scores_mean + valid_scores_std, alpha=0.2, color=\"g\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "    print \"Best parameter is {}\".format(param_range[valid_scores_mean.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_validation_curve(train_scores, valid_scores, \n",
    "                      param_range[param_name], semilogx=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(GradientBoostingClassifier(max_depth=5, n_estimators=32),\n",
    "                            X_train, y_train, scoring='log_loss', cv=5, n_jobs=-1)\n",
    "print\"{0:.4f} ({1:.4f})\".format(cv_scores.mean(), cv_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#param_name = 'max_depth'\n",
    "param_name = 'n_estimators'\n",
    "\n",
    "param_range = {\n",
    "    #'max_depth': np.logspace(0, 8, base=2, num=9),\n",
    "    'max_depth': [6, 7, 8, 9, 10, 11, 12],\n",
    "    'n_estimators': np.logspace(2, 11, base=2, num=10).astype(int),\n",
    "    #'n_estimators': [40, 60, 80, 100, 120, 140, 160],\n",
    "}\n",
    "\n",
    "fixed_params = {\n",
    "    'max_depth': 10\n",
    "}\n",
    "\n",
    "train_scores, valid_scores = validation_curve(RandomForestClassifier(**fixed_params), \n",
    "                                              X_train, y_train, \n",
    "                                              scoring='log_loss',\n",
    "                                              cv = 3,\n",
    "                                              param_name=param_name, \n",
    "                                              param_range=param_range[param_name], \n",
    "                                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_validation_curve(train_scores, valid_scores, \n",
    "                      param_range[param_name], semilogx=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(RandomForestClassifier(max_depth=10, n_estimators=2048),\n",
    "                            X_train, y_train, scoring='log_loss', cv=5, n_jobs=-1)\n",
    "print\"{0:.4f} ({1:.4f})\".format(cv_scores.mean(), cv_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （おまけ）モデルのアベレージング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimators = []\n",
    "\n",
    "# ハイパーパラメータは、モデルごとに交差検証して決める\n",
    "#estimators.append(('lr', LogisticRegression(C=1)))\n",
    "estimators.append(('gbc', GradientBoostingClassifier(n_estimators=32, max_depth=5)))\n",
    "estimators.append(('rf', RandomForestClassifier(n_estimators=2048, max_depth=10)))\n",
    "#estimators.append(('et', ExtraTreesClassifier(n_estimators=250, max_depth=12)))\n",
    "#estimators.append(('xgb', XGBClassifier(n_estimators=32, max_depth=6, learning_rate=0.1, \n",
    "#                                        colsample_bytree=0.7, reg_alpha=0.0, reg_lambda=1.0, \n",
    "#                                        min_child_weight=6, subsample=1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = VotingClassifier(estimators=estimators, voting='soft', weights=[1, 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 各モデルの予測の相関関係をみる。相関関係の薄いモデルをVoting ensembleに入れる\n",
    "\n",
    "pred_prob = {}\n",
    "for model_name in model.named_estimators:\n",
    "    curr_model = model.named_estimators[model_name]\n",
    "    curr_model.fit(X_train, y_train)\n",
    "    pred_prob[model_name]  = curr_model.predict_proba(X_test).flatten()#[:, 1]\n",
    "    \n",
    "df_pred = pd.DataFrame(pred_prob)\n",
    "df_pred.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = cross_val_score(model, X_train, y_train, cv=5, scoring='log_loss', n_jobs=-1)\n",
    "print(\"({0:.4f}) +/- ({1:.4f})\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# いい感じに全てのモデルのハイパーパラメータが決まったら、全てのモデルをアンサンブル学習\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 予測\n",
    "y_test_pred = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(y_test_pred, columns=outcome_labels, index=df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result.to_csv(\"../output/submission02.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
